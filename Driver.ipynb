{
 "metadata": {
  "name": "",
  "signature": "sha256:53cf410e48716530e37836d6d7d5be7d9e4dfd68a26ed5a21a4d7f0cab730ffd"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# initial values\n",
      "template_idf_path = \"test/campusbuilding.idf\"\n",
      "eplus_basic_folder = \"test/basic_files\"\n",
      "output_folder = sys.argv[1]\n",
      "chain = chain\n",
      "\n",
      "\n",
      "count = 1\n",
      "eplusout_file_name = \"eplusout.csv\"\n",
      "result_folder_name = \"result\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# check output path\n",
      "if os.path.exists(output_folder):\n",
      "    shutil.rmtree(output_folder)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# prepares jobs\n",
      "markup_value_pairs = dict(zip(['@@ROOF','@@WALL@@','@@WIN@@','@@SHGC@@',\n",
      "                               '@@EPD@@','@@LPD@@','@@HSP@@','@@CSP@@',\n",
      "                               '@@OCC@@','@@INF@@','@@Boiler@@','@@COP@@'], chain))\n",
      "pathes = prepare_job_folders(output_folder, template_idf_path,\n",
      "                             eplus_basic_folder, markup_value_pairs)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# run jobs\n",
      "run_eplus_multi(pathes)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "After processing"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# post-processing: gathering eplusout.csv files\n",
      "eplus_out_csv_pathes = []\n",
      "for root, dirs, files in os.walk(output_folder):\n",
      "    for file in files:\n",
      "        if file.endswith(eplusout_file_name):\n",
      "            eplus_out_csv_pathes.append(os.path.join(root, file))\n",
      "eplus_out_csv_pathes = sorted(eplus_out_csv_pathes)\n",
      "result_path = os.path.join(output_folder, result_folder_name)\n",
      "os.makedirs(result_path)\n",
      "dest_pathes = []\n",
      "for path in eplus_out_csv_pathes:\n",
      "    path = path.replace(output_folder + \"/\", '')\n",
      "    path = path.replace(\"/\", \"_\")\n",
      "    path = os.path.join(result_path, path)\n",
      "    dest_pathes.append(path)\n",
      "for orig, dest in zip(eplus_out_csv_pathes, dest_pathes):\n",
      "    shutil.copyfile(orig, dest)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# gathering csv files into a csv file\n",
      "csv_sum = []\n",
      "with open(dest_pathes[0]) as csv_file:\n",
      "    rows = csv.reader(csv_file, delimiter='|')\n",
      "    contents = [row for row in rows]\n",
      "    csv_sum.extend(contents[0])\n",
      "\n",
      "for file in dest_pathes:\n",
      "    with open(file) as csv_file:\n",
      "        rows = csv.reader(csv_file, delimiter='|')\n",
      "        contents = [row for row in rows]\n",
      "        csv_sum.extend(contents[1])\n",
      "\n",
      "csv_sum_file_name = \"csv_sum.csv\"\n",
      "csv_sum_file_path = os.path.join(result_path, csv_sum_file_name)\n",
      "with open(csv_sum_file_path, \"wb\") as file:\n",
      "    for row in csv_sum:\n",
      "        file.write(\"%s\\n\" % row)\n",
      "\n",
      "# generating csv file for markup value_pairs\n",
      "input_param_val_name = \"input_parameters_values.csv\"\n",
      "input_param_val_path = os.path.join(result_path, input_param_val_name)\n",
      "with open(input_param_val_path, \"wb\") as file:\n",
      "    out = csv.writer(file, delimiter='|', quoting=csv.QUOTE_NONE)\n",
      "    header = [\"JOB_ID\"]\n",
      "    header.extend(markup_value_pairs[0].keys())\n",
      "    out.writerow(header)\n",
      "    for index, item in enumerate(markup_value_pairs):\n",
      "        row = [index]\n",
      "        row.extend(item.values())\n",
      "        out.writerow(row)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}